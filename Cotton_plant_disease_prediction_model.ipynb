{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cotton_plant_disease_prediction_model.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Cotton Plant Disease Prediction & Get Cure App"
      ],
      "metadata": {
        "id": "NyshArX9rbbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "aKbZTNMurcZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "IG_9YWz2sM2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for accuracy and loss graph\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "r5UIdvscrwNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__\n",
        "\n"
      ],
      "metadata": {
        "id": "zKQ0piP7r32I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = '/content/drive/MyDrive/Cotton Disease/train'\n",
        "validation_data_path = '/content/drive/MyDrive/Cotton Disease/val'"
      ],
      "metadata": {
        "id": "CihXl3IAstR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Show augmented images\n",
        "def plot_images(image_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(image_arr, axes):\n",
        "    ax.imshow(img)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Ik1S2r5IOnVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "# It generate more images using below parameters\n",
        "\n",
        "training_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                      rotation_range = 40,\n",
        "                                      width_shift_range = 0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range = 0.20,\n",
        "                                      zoom_range = 0.20,\n",
        "                                      horizontal_flip = True,\n",
        "                                      fill_mode = 'nearest')\n",
        "\n",
        "# This is a generator that will read pictures found in at train_data_path, and indefinitely generate batches\n",
        "# of augmented image data"
      ],
      "metadata": {
        "id": "Fo7pKLTcPFSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = training_datagen.flow_from_directory(train_data_path,     # This is a target directory\n",
        "                                      target_size = (150, 150),  # all image resized to 150x150\n",
        "                                      batch_size = 32, \n",
        "                                      class_mode = 'binary') # Since we use binary_crossentropy loss, we need binary labels \n",
        " \n",
        "training_data.class_indices                                        "
      ],
      "metadata": {
        "id": "qtRKNBD0Qdvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for validation\n",
        "# Only rescalling\n",
        "valid_design = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# This is a similar generator , for validation data\n",
        "valid_data = valid_design.flow_from_directory(validation_data_path,\n",
        "                                               target_size = (150, 150),\n",
        "                                               batch_size= 32,\n",
        "                                               class_mode= 'binary')\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwJekrvHTAY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing augmented images\n",
        "images = [training_data[0][0][0] for i in range(5)]\n",
        "plot_images(images)"
      ],
      "metadata": {
        "id": "dqE_9i-PUj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Cotton Disease/decease_prediction.h5'\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "callback_list = [checkpoint]"
      ],
      "metadata": {
        "id": "oinL7KVNRoCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hVeNUdkyRqel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building cnn model\n"
      ],
      "metadata": {
        "id": "CSnqcM9TcFtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D"
      ],
      "metadata": {
        "id": "KNEpJnmNcFDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, strides = (1,1), kernel_size  = 3, padding = 'valid', activation = 'relu', input_shape = [150, 150, 3] ))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten() )\n",
        "model.add(Dense( units = 128, activation= 'relu' ))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense( units = 256, activation= 'relu' ))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense( units = 4, activation= 'softmax' ))"
      ],
      "metadata": {
        "id": "hCOzHcnEcOrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile cnn model\n",
        "model.compile(optimizer = Adam(lr = 0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']  )"
      ],
      "metadata": {
        "id": "SWa9CM4SdL45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "rWY4jz5RfaX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_data, epochs = 500, verbose = 1, validation_data = valid_data, callbacks = callback_list )  "
      ],
      "metadata": {
        "id": "ovrL1ItvfkJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path2 = 'content/drive/MyDrive/'\n",
        "# model_path"
      ],
      "metadata": {
        "id": "gSD0xqF9gBDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend( ['train', 'test'], loc = 'upper left' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4TufpJyGhqSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')"
      ],
      "metadata": {
        "id": "fId_xBJxijO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-WzhyT56meR0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}